#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦æœç´¢æå– - æœ€ç»ˆç‰ˆ
"""

from playwright.sync_api import sync_playwright
import json
import time
import sys

def extract_notes(page, limit=10):
    """æå–ç¬”è®°ä¿¡æ¯"""
    notes = []
    
    # è·å–é¡µé¢ä¸»è¦å†…å®¹
    container = page.query_selector('main') or page.query_selector('[class*="container"]') or page.query_selector('body')
    
    if container:
        # æŸ¥æ‰¾æ‰€æœ‰å¯ç‚¹å‡»çš„é“¾æ¥ï¼ˆé€šå¸¸æ˜¯ç¬”è®°ï¼‰
        links = container.query_selector_all('a')[:limit*2]
        
        for link in links:
            try:
                href = link.get_attribute('href')
                if href and '/note/' in href:
                    # è·å–çˆ¶å…ƒç´ çš„æ–‡æœ¬å†…å®¹ä½œä¸ºæ ‡é¢˜
                    parent = link.evaluate_handle('el => el.parentElement')
                    text = ''
                    if parent:
                        text = parent.inner_text()[:200]
                    
                    if text and len(text) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                        note = {
                            'title': text.split('\n')[0].strip()[:100],
                            'url': f'https://www.xiaohongshu.com{href}' if href.startswith('/') else href
                        }
                        
                        # æŸ¥æ‰¾ç‚¹èµæ•°ï¼ˆå¯èƒ½åœ¨é™„è¿‘ï¼‰
                        like_elem = link.query_selector('[class*="like"]') or link.query_selector('[class*="collect"]')
                        if like_elem:
                            note['likes'] = like_elem.inner_text().strip()
                        
                        if note['title'] not in [n['title'] for n in notes]:
                            notes.append(note)
                            
            except Exception:
                continue
    
    return notes[:limit]

def search(keyword):
    """æœç´¢å¹¶æå–"""
    print(f"\nğŸ” æœç´¢: {keyword}")
    
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-setuid-sandbox']
        )
        
        page = browser.new_page()
        
        try:
            # è®¿é—®æœç´¢é¡µ
            url = f'https://www.xiaohongshu.com/search?keyword={keyword}'
            page.goto(url, timeout=20000, wait_until='domcontentloaded')
            time.sleep(3)
            
            print(f"   ğŸ“„ æ ‡é¢˜: {page.title()}")
            
            # æå–ç¬”è®°
            notes = extract_notes(page)
            print(f"   âœ… æå– {len(notes)} æ¡ç¬”è®°")
            
            return {
                'keyword': keyword,
                'url': url,
                'notes': notes,
                'count': len(notes)
            }
            
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {e}")
            return {'keyword': keyword, 'error': str(e)}
        finally:
            browser.close()

def main():
    if len(sys.argv) > 1:
        keywords = sys.argv[1:]
    else:
        keywords = ["ç©¿æ­", "ç¾å¦†"]
    
    print("="*60)
    print("  ğŸ¦ å°çº¢ä¹¦æœç´¢æå–")
    print("="*60)
    
    results = {}
    for kw in keywords:
        result = search(kw)
        results[kw] = result
        
        if 'notes' in result:
            print(f"\nğŸ“ ç»“æœ:")
            for i, note in enumerate(result['notes'][:5], 1):
                print(f"   {i}. {note['title'][:50]}")
                if note.get('url'):
                    print(f"      ğŸ”— {note['url'][:60]}...")
    
    # ä¿å­˜ç»“æœ
    output = '/root/.openclaw/workspace/xiaohongshu-results.json'
    with open(output, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output}")

if __name__ == "__main__":
    main()
